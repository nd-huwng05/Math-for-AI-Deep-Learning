# ğŸ“š Math Roadmap for Understanding ML/DL Research Papers

This guide helps you **truly understand** the mathematical foundations behind modern ML/DL papers â€” not just how to solve problems, but why things work. Ideal for those who have experience solving calculus, linear algebra, and statistics problems, but want to go deeper.

---

## ğŸ§® 1. Core Math Foundations (Essential)

### ğŸ“˜ Calculus
- **Books**:
  - *Calculus* â€“ James Stewart
  - *Thomas' Calculus* â€“ George B. Thomas
- **What to focus on**:
  - Limits & Derivatives
  - Chain Rule, Gradients, Partial Derivatives
  - Optimization via Derivatives
  - Taylor Expansion
- **Suggested Chapters**: 2â€“4, 9, 14â€“15

---

### ğŸ“— Linear Algebra
- **Books**:
  - *Introduction to Linear Algebra* â€“ Gilbert Strang
  - *Linear Algebra and Its Applications* â€“ Gilbert Strang
- **Key Topics**:
  - Vectors, Matrices, Linear Transformations
  - Eigenvalues & Eigenvectors
  - Singular Value Decomposition (SVD)
- **Suggested Chapters**: 1â€“3, 5â€“7

---

### ğŸ² Probability & Statistics
- **Books**:
  - *Introduction to Probability* â€“ Blitzstein & Hwang
  - *A First Course in Probability* â€“ Sheldon Ross
- **Key Topics**:
  - Bayes' Theorem, Conditional Probability
  - Random Variables, Expectation
  - Distributions: Bernoulli, Binomial, Normal, etc.
  - Law of Large Numbers, Central Limit Theorem
- **Suggested Chapters**: 1â€“7, 12

---

## ğŸ§  2. Advanced Math for Research

### ğŸ“˜ Mathematical Statistics
- **Books**:
  - *Statistical Inference* â€“ Casella & Berger
  - *All of Statistics* â€“ Larry Wasserman
- **Key Topics**:
  - Estimation (MLE, MAP), Confidence Intervals
  - Bayesian Inference, Hypothesis Testing
- **Suggested Chapters**:
  - Casella: 5â€“7, 10
  - Wasserman: 1â€“6, 8â€“11, 18â€“20

---

### ğŸ§© Convex Optimization
- **Book**: *Convex Optimization* â€“ Stephen Boyd & Lieven Vandenberghe
- **Key Topics**:
  - Convex Sets & Functions
  - Duality Theory
  - Gradient-Based Optimization
- **Suggested Chapters**: 2â€“5

---

### ğŸ§  Information Theory
- **Book**: *Elements of Information Theory* â€“ Cover & Thomas
- **Key Topics**:
  - Entropy, KL-Divergence, Mutual Information
  - Applications in VAE, GANs, RL
- **Suggested Chapters**: 2â€“3, 8

---

### ğŸ“ Real Analysis (for Proofs & Convergence)
- **Books**:
  - *Understanding Analysis* â€“ Stephen Abbott *(easier)*
  - *Principles of Mathematical Analysis* â€“ Walter Rudin *(rigorous)*
- **Key Topics**:
  - Limits, Continuity, Sequences
  - Proof-based Thinking, Convergence
- **Suggested Chapters (Abbott)**: 1â€“6

---

## ğŸ¤– 3. Math for ML & Deep Learning

### ğŸ“˜ Mathematics for Machine Learning *(FREE)*  
ğŸ”— [https://mml-book.github.io/](https://mml-book.github.io/)
- **Key Topics**:
  - Linear Algebra for ML
  - Geometry, Probability, Optimization
  - Regression, PCA
- **Suggested Chapters**: 2, 3, 5â€“8

---

### ğŸ“— Pattern Recognition and Machine Learning â€“ Bishop
- **Key Topics**:
  - Probabilistic Models
  - Neural Networks
  - EM Algorithm, Mixture Models
- **Suggested Chapters**: 1â€“3, 5, 9

---

### ğŸ“™ Deep Learning â€“ Goodfellow, Bengio, Courville
- **Key Topics**:
  - Linear Algebra, Probability, Optimization
  - Training Deep Nets, CNNs, Autoencoders, GANs
- **Suggested Chapters**: 2â€“4, 6, 8â€“9, 18, 20

---

## âœ… Summary Table

| Topic               | Book                          | Chapters to Read     |
|--------------------|-------------------------------|----------------------|
| Calculus           | Stewart / Thomas              | 2â€“4, 9, 14â€“15        |
| Linear Algebra     | Strang                        | 1â€“3, 5â€“7             |
| Probability        | Blitzstein / Ross             | 1â€“7, 12              |
| Statistics         | Casella / Wasserman           | 5â€“7, 10 / 1â€“6, 18â€“20 |
| Optimization       | Boyd                          | 2â€“5                  |
| Information Theory | Cover & Thomas                | 2â€“3, 8               |
| Real Analysis      | Abbott                        | 1â€“6                  |
| ML Foundations     | Math for ML (MML book)        | 2, 3, 5â€“8            |
| ML Theory          | Bishop                        | 1â€“3, 5, 9            |
| Deep Learning      | Goodfellow et al.             | 2â€“4, 6, 8â€“9, 18, 20  |